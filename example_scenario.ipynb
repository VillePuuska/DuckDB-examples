{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario\n",
    "\n",
    "In short: read records from multiple JSON and Parquet files with different schemas, explode/unnest and aggregate the data, and write the results to Postgres.\n",
    "\n",
    "## Data\n",
    "\n",
    "The data generated with `generate_example_data.py` for this scenario contains 25 JSON files and 5 Parquet files. Each JSON file and each row in the Parquet files contains a record with the following fields:\n",
    "| Field | Optional | Data type | Possible values |\n",
    "| --- | --- | --- | --- |\n",
    "| id |  | int |  | [1, 600)\n",
    "| timestamp |  | str | ISO format timestamp |\n",
    "| col1 | x | float | [100, 200) |\n",
    "| col2 | x | float | [200, 300) |\n",
    "| col3 | x | float | [300, 400) |\n",
    "| tags | x | List[str] | \"a\", \"b\", \"c\", \"d\" |\n",
    "\n",
    "## Task 1\n",
    "\n",
    "Find the count and average of values in the fields `col1`, `col2`, and `col3` aggregated by the different tags. Write the result to Postgres as a new table.\n",
    "\n",
    "## Task 2\n",
    "\n",
    "Find the most common tag(s) for every month (ignoring the year). Write the result to Postgres as a new table.\n",
    "\n",
    "## Plan of attack\n",
    "\n",
    "We'll work through this problem in the following steps:\n",
    "- read JSON and Parquet files and combine schemas,\n",
    "- explode tags and get Task 1 aggregates,\n",
    "- convert str timestamp to actual timestamp and extract month,\n",
    "- get tag ranks by month and get top tags as a list by month for Task 2,\n",
    "- connect and write results to Postgres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
